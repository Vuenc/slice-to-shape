#!/bin/sh
 
#SBATCH --job-name=dilabSSM
#SBATCH --output=log/dilab-%A.out  # Standard output of the script (Can be absolute or relative path). %A adds the job id to the file name so you can launch the same script multiple times and get different logging files
#SBATCH --error=log/dilab-%A.err  # Standard error of the script
#SBATCH --time=0-24:00:00  # Limit on the total run time (format: days-hours:minutes:seconds)
#SBATCH --gres=gpu:1  # Number of GPUs if needed
#SBATCH --cpus-per-task=12  # Number of CPUs (Don't use more than 24 per GPU)
#SBATCH --mem=126G  # Memory in GB (Don't use more than 126G per GPU)
 
# load python module
source /home/guests/alexander_baumann/.bashrc
source /home/guests/alexander_baumann/miniconda3/bin/activate surfmnet3
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH::/home/guests/alexander_baumann/miniconda3/envs/surfmnet3/lib:/home/guests/alexander_baumann/miniconda3/lib:/home/guests/alexander_baumann/miniconda3/envs/surfmnet3/lib:/home/guests/alexander_baumann/miniconda3/lib

# run the program
srun python train_surfmnet.py /home/guests/alexander_baumann/tum-data-lab/config/heart3.yml  